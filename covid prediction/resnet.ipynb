{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a99d46c4-d0be-4cbe-b387-764da37610c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get update && apt-get install -y python3-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89fb5f4b-c3bd-4d5e-8813-15f9adc24afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd031e1-398d-4514-bf77-c22f370b2a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -c \"import cv2; print(cv2.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a415eec-e8d9-4b6f-a2f6-d7fc7846915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c6b2d1-f4f3-4ab8-a496-d8bdf970c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, copy, cv2, sys, random\n",
    "# from datetime import datetime, timezone, timedelta\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from pylab import rcParams\n",
    "\n",
    "# import torchvision.transforms.functional as TF\n",
    "# from imgaug import augmentables\n",
    "# import imgaug as ia\n",
    "# import imgaug.augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a13cdbdc-3b26-47d2-aea2-79c093b77c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d808713c-6304-4a3d-86a6-3656f24d41cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "# vgg19 = models.vgg19_bn(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f8d266f-f70a-40f6-809d-8b4301d45594",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2022\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea853262-64b1-41ff-8ddc-7a92308a24d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "### 데이터 디렉토리 설정 ###\n",
    "DATA_DIR= 'data'\n",
    "NUM_CLS = 2\n",
    "\n",
    "EPOCHS = 45\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "EARLY_STOPPING_PATIENCE = 15\n",
    "INPUT_SHAPE = 128\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5ee62c9-1d61-47c9-8517-651ca3a7160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -c \"import torchvision; print(torchvision.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6877d316-af1e-4d44-a07e-e39c7d974c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision.models.mobilenetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "970aef7d-e854-45af-bd05-d339c6510872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet121 = torch.hub.load('pytorch/vision:v0.8.2', 'densenet121', pretrained=False) #161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b99fbb5-22b1-44bc-8c83-08248fde8aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1666674-9231-4f9e-8aaf-e927c0b92dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet121.features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce55163c-25e5-4026-b290-7b1802eeb727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet121.features[4].denselayer2.norm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36a305-ba54-4c3e-b236-0ac5a2408573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa307948-a608-456d-a3f1-e37e5edc001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Densenet121(nn.Module):\n",
    "#     def __init__(self, embedding_dimension=128):\n",
    "#         super().__init__()\n",
    "#         self.model = densenet121.features[:4]\n",
    "#         # self.model = densenet121\n",
    "#         self.layer1 = densenet121.features[4].denselayer1\n",
    "#         self.dropout1 = nn.Dropout(0.9)\n",
    "#         self.layer2 = densenet121.features[4].denselayer2\n",
    "#         self.layer3 = densenet121.features[4].denselayer3\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "#         # embedding\n",
    "#         # input_features_fc_layer = densenet121.classifier.in_features # fc layer 채널 수 얻기\n",
    "#         # self.classifier = nn.Linear(32768, 2, bias=True) # fc layer 수정\n",
    "#         # print(self.model)\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(32768 ,512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.8),\n",
    "#             nn.Linear(512,128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.8),\n",
    "#             nn.Linear(128,2)\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         # x = self.model(x).view(-1,  16 * 16 * 128) # embedding 생성\n",
    "#         x1 = self.model(x)\n",
    "#         x2 = self.layer1(x1)\n",
    "#         y = torch.cat((x1, x2), 1)\n",
    "#         x3 = self.layer2(y)\n",
    "#         y2 = torch.cat((x1, x2, x3), 1)\n",
    "#         x = self.layer3(y2)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.classifier(x)\n",
    "#         output = self.softmax(x)\n",
    "\n",
    "#         return output\n",
    "#         # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "775062cd-62c1-42ea-b855-f81d595df1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug = Densenet121()\n",
    "# input = torch.Tensor(32, 3, 128, 128)\n",
    "# Debug(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2beb8f17-d395-46ea-88a1-fa685399c272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.8.2\n"
     ]
    }
   ],
   "source": [
    "resnet18 = torch.hub.load('pytorch/vision:v0.8.2', 'resnet18', pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4729b6a5-abd8-43c7-a6c8-2170c63ad850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaab5765-695d-45e1-97b5-6f0c13ce1422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6769ee23-87a7-4fe3-a5b9-9e56b5f51806",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18(nn.Module):\n",
    "    def __init__(self, embedding_dimension=128):\n",
    "        super().__init__()\n",
    "        self.model = resnet18\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        # self.conv1 = self.model.conv1\n",
    "        # self.bn1 = self.model.bn1\n",
    "        # self.relu = self.model.relu \n",
    "        # self.maxpool = self.model.maxpool\n",
    "        # self.layer1 = self.model.layer1\n",
    "        \n",
    "        # self.model.fc = nn.Linear(65536, 2, bias=True)\n",
    "        \n",
    "        # self.fc = nn.Linear(65536, 2, bias=True) # fc layer 수정\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1000 ,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(500,100),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.8),\n",
    "            nn.Linear(100,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(20,2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.fc(x)\n",
    "        output = self.softmax(x)\n",
    "\n",
    "        return output\n",
    "        # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7270a61-f15c-46a5-b0b0-a378da282544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Debug = Resnet18()\n",
    "input = torch.Tensor(32, 3, 128, 128)\n",
    "Debug(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99139fbd-028e-4b5d-a9bb-1bd1b5dd7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# class custom_CNN(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(custom_CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=8, out_channels=25, kernel_size=5)\n",
    "        \n",
    "#         self.fc1 = nn.Linear(in_features=25*29*29, out_features=128)\n",
    "#         self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x))) # (32, 3, 128, 128) -> (32, 8, 62, 62)\n",
    "#         x = self.pool(F.relu(self.conv2(x))) # (32, 8, 62, 62) -> (32, 25, 29, 29)\n",
    "        \n",
    "#         x = torch.flatten(x,1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "        \n",
    "#         output = self.softmax(x)\n",
    "        \n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df645e66-95e5-4ecf-8df5-6bc52527d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug = custom_CNN(2)\n",
    "# input = torch.Tensor(2, 3, 128, 128)\n",
    "# Debug(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8089fce6-e5df-4e7e-8379-9d660a7318a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, mode, input_shape):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Loading dataset\n",
    "        self.db = self.data_loader()\n",
    "        \n",
    "        # Dataset split\n",
    "        if self.mode == 'train':\n",
    "            self.db = self.db[:int(len(self.db) * 0.9)]\n",
    "        elif self.mode == 'val':\n",
    "            self.db = self.db[int(len(self.db) * 0.9):]\n",
    "            self.db.reset_index(inplace=True)\n",
    "        else:\n",
    "            print(f'!!! Invalid split {self.mode}... !!!')\n",
    "            \n",
    "        # Transform function\n",
    "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
    "                                             transforms.RandomRotation(30),\n",
    "                                             # transforms.RandomHorizontalFlip(),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        # (COVID : 1, No : 0)\n",
    "        db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
    "        \n",
    "        return db\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "\n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(os.path.join(self.data_dir,'train',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
    "\n",
    "        # Preprocessing images\n",
    "        trans_image = self.transform(Image.fromarray(cvimg))\n",
    "        \n",
    "        # tmp = data['COVID']\n",
    "        # concat_data = pd.concat([tmp, tmp, tmp, tmp])\n",
    "        return trans_image, data['COVID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce48aa-2e7c-4d22-bb1e-835d98365835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d7bc108-5511-4cba-ba1e-3b9c2efb4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossEarlyStopper():\n",
    "    \"\"\"Early stopper\n",
    "    \n",
    "    Attributes:\n",
    "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가, 감소 시 0으로 리셋\n",
    "        min_loss (float): 최소 loss\n",
    "        stop (bool): True 일 때 학습 중단\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int)-> None:\n",
    "        self.patience = patience\n",
    "\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.stop = False\n",
    "        self.save_model = False\n",
    "\n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        \"\"\"Early stopping 여부 판단\"\"\"  \n",
    "\n",
    "        if self.min_loss == np.Inf:\n",
    "            self.min_loss = loss\n",
    "            return None\n",
    "\n",
    "        elif loss > self.min_loss:\n",
    "            self.patience_counter += 1\n",
    "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "\n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True\n",
    "                \n",
    "        elif loss <= self.min_loss:\n",
    "            self.patience_counter = 0\n",
    "            self.save_model = True\n",
    "            msg = f\"Validation loss decreased {self.min_loss} -> {loss}\"\n",
    "            self.min_loss = loss\n",
    "        \n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9894a709-0504-4fdd-813d-8008d2abc38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \"\"\" epoch에 대한 학습 및 검증 절차 정의\"\"\"\n",
    "    \n",
    "    def __init__(self, loss_fn, model, device, metric_fn, optimizer=None, scheduler=None):\n",
    "        \"\"\" 초기화\n",
    "        \"\"\"\n",
    "        self.loss_fn = loss_fn\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.metric_fn = metric_fn\n",
    "\n",
    "    def train_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 학습 절차\"\"\"\n",
    "        \n",
    "        self.model.train()\n",
    "        train_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        prob_lst = []\n",
    "\n",
    "        for batch_index, (img, label) in enumerate(dataloader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device).float()\n",
    "            \n",
    "            pred = self.model(img)\n",
    "            \n",
    "            loss = self.loss_fn(pred[:,1], label)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            train_total_loss += loss.item()\n",
    "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
    "            target_lst.extend(label.cpu().tolist())\n",
    "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
    "        self.train_mean_loss = train_total_loss / batch_index\n",
    "        self.train_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
    "        msg = f'Epoch {epoch_index}, Train loss: {self.train_mean_loss}, Acc: {self.train_score}, F1-Macro: {f1}'\n",
    "        print(msg)\n",
    "\n",
    "    def validate_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        val_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        prob_lst = []\n",
    "\n",
    "        for batch_index, (img, label) in enumerate(dataloader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device).float()\n",
    "            pred = self.model(img)\n",
    "            \n",
    "            loss = self.loss_fn(pred[:,1], label)\n",
    "            val_total_loss += loss.item()\n",
    "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
    "            target_lst.extend(label.cpu().tolist())\n",
    "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
    "        self.val_mean_loss = val_total_loss / batch_index\n",
    "        self.validation_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
    "        msg = f'Epoch {epoch_index}, Val loss: {self.val_mean_loss}, Acc: {self.validation_score}, F1-Macro: {f1}'\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85fedad8-4748-4fbf-b9f4-951c1b6df56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "667f55ee-fab7-4e96-ac42-9270151cc67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def get_metric_fn(y_pred, y_answer):\n",
    "    \"\"\" 성능을 반환하는 함수\"\"\"\n",
    "    \n",
    "    assert len(y_pred) == len(y_answer), 'The size of prediction and answer are not same.'\n",
    "    accuracy = accuracy_score(y_answer, y_pred)\n",
    "    f1 = f1_score(y_answer, y_pred, average='macro')\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71dd7696-d70f-4ad0-b82b-6a8dd17eaeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d742890-8992-483c-98d1-825f731e8aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset..\n",
      "Loading val dataset..\n",
      "Train set samples: 581 Val set samples: 65\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train', input_shape=INPUT_SHAPE)\n",
    "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val', input_shape=INPUT_SHAPE)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print('Train set samples:',len(train_dataset),  'Val set samples:', len(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3b4fffd-e619-4f00-9b76-6a78260d881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = Resnet18().to(DEVICE)\n",
    "\n",
    "# # Save Initial Model\n",
    "# torch.save(model.state_dict(), 'initial.pt')\n",
    "\n",
    "# Set optimizer, scheduler, loss function, metric function\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler =  optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.0005, epochs=EPOCHS, steps_per_epoch=len(train_dataloader))\n",
    "loss_fn = nn.BCELoss()\n",
    "metric_fn = get_metric_fn\n",
    "\n",
    "\n",
    "# Set trainer\n",
    "trainer = Trainer(loss_fn, model, DEVICE, metric_fn, optimizer, scheduler)\n",
    "\n",
    "# Set earlystopper\n",
    "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1f4aea1-2e6a-4ced-b12d-737eefb02e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train loss: 0.759371260801951, Acc: 0.45611015490533563, F1-Macro: 0.32122153209109733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% 1/45 [01:01<45:09, 61.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.9811893105506897, Acc: 0.5076923076923077, F1-Macro: 0.336734693877551\n",
      "Epoch 1, Train loss: 0.7482860154575772, Acc: 0.46815834767641995, F1-Macro: 0.3693235111237577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4% 2/45 [02:00<43:30, 60.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Val loss: 0.9927087128162384, Acc: 0.5076923076923077, F1-Macro: 0.336734693877551\n",
      "Early stopping counter 1/15\n",
      "Epoch 2, Train loss: 0.7329949405458238, Acc: 0.5249569707401033, F1-Macro: 0.49868697478991597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7% 3/45 [02:57<41:41, 59.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Val loss: 1.2041200995445251, Acc: 0.5076923076923077, F1-Macro: 0.4222222222222223\n",
      "Early stopping counter 2/15\n",
      "Epoch 3, Train loss: 0.7279444634914398, Acc: 0.5611015490533563, F1-Macro: 0.5534608255346082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9% 4/45 [03:55<40:26, 59.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Val loss: 2.2069491147994995, Acc: 0.5384615384615384, F1-Macro: 0.4583333333333333\n",
      "Early stopping counter 3/15\n",
      "Epoch 4, Train loss: 0.7400914827982584, Acc: 0.5697074010327022, F1-Macro: 0.5602961832800543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11% 5/45 [04:54<39:22, 59.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Val loss: 2.7941823599976487, Acc: 0.5076923076923077, F1-Macro: 0.336734693877551\n",
      "Early stopping counter 4/15\n",
      "Epoch 5, Train loss: 0.7320099605454339, Acc: 0.5628227194492255, F1-Macro: 0.561876543796314\n",
      "Epoch 5, Val loss: 0.8105417937040329, Acc: 0.6, F1-Macro: 0.5775000000000001\n",
      "Validation loss decreased 0.9811893105506897 -> 0.8105417937040329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13% 6/45 [05:53<38:22, 59.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train loss: 0.7202766338984171, Acc: 0.5456110154905336, F1-Macro: 0.522049108812165\n",
      "Epoch 6, Val loss: 0.8285916447639465, Acc: 0.6153846153846154, F1-Macro: 0.6094688776736361\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16% 7/45 [06:45<36:02, 56.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train loss: 0.7128705614142947, Acc: 0.5972461273666093, F1-Macro: 0.5918179853004755\n",
      "Epoch 7, Val loss: 1.0288378298282623, Acc: 0.6923076923076923, F1-Macro: 0.6904761904761905\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18% 8/45 [07:40<34:44, 56.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train loss: 0.7046211957931519, Acc: 0.5869191049913941, F1-Macro: 0.5740469208211143\n",
      "Epoch 8, Val loss: 1.4564145803451538, Acc: 0.5230769230769231, F1-Macro: 0.43223443223443225\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 9/45 [08:38<34:05, 56.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train loss: 0.6816960109604729, Acc: 0.6075731497418244, F1-Macro: 0.5985720865960387\n",
      "Epoch 9, Val loss: 1.0948229134082794, Acc: 0.6, F1-Macro: 0.5305555555555556\n",
      "Early stopping counter 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22% 10/45 [09:35<33:13, 56.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train loss: 0.7356292539172702, Acc: 0.6092943201376936, F1-Macro: 0.6044952243863674\n",
      "Epoch 10, Val loss: 3.72081196308136, Acc: 0.5384615384615384, F1-Macro: 0.4583333333333333\n",
      "Early stopping counter 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24% 11/45 [10:29<31:47, 56.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train loss: 0.6995176292128034, Acc: 0.5800344234079173, F1-Macro: 0.5596516077729735\n",
      "Epoch 11, Val loss: 1.168503612279892, Acc: 0.7076923076923077, F1-Macro: 0.7051802339460491\n",
      "Early stopping counter 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27% 12/45 [11:16<29:24, 53.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train loss: 0.6635062793890635, Acc: 0.6712564543889845, F1-Macro: 0.67037762021737\n",
      "Epoch 12, Val loss: 0.7939962297677994, Acc: 0.7384615384615385, F1-Macro: 0.7292330311198236\n",
      "Validation loss decreased 0.8105417937040329 -> 0.7939962297677994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29% 13/45 [12:01<27:09, 50.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train loss: 0.7323876619338989, Acc: 0.6041308089500861, F1-Macro: 0.5946183715568499\n",
      "Epoch 13, Val loss: 1.389382466673851, Acc: 0.7230769230769231, F1-Macro: 0.7214285714285714\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31% 14/45 [12:47<25:33, 49.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train loss: 0.6296028229925368, Acc: 0.6660929432013769, F1-Macro: 0.6660128007585634\n",
      "Epoch 14, Val loss: 0.9513865411281586, Acc: 0.7384615384615385, F1-Macro: 0.738213693437574\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33% 15/45 [13:34<24:20, 48.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train loss: 0.676645557085673, Acc: 0.6385542168674698, F1-Macro: 0.6347880747126438\n",
      "Epoch 15, Val loss: 0.9609461724758148, Acc: 0.7230769230769231, F1-Macro: 0.7075\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36% 16/45 [14:21<23:17, 48.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train loss: 0.6423371964030795, Acc: 0.6884681583476764, F1-Macro: 0.6873976308318842\n",
      "Epoch 16, Val loss: 0.8057505488395691, Acc: 0.7230769230769231, F1-Macro: 0.7214285714285714\n",
      "Early stopping counter 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38% 17/45 [15:06<22:02, 47.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train loss: 0.6253051675028272, Acc: 0.6833046471600689, F1-Macro: 0.6812185405186193\n",
      "Epoch 17, Val loss: 0.8495105355978012, Acc: 0.6307692307692307, F1-Macro: 0.6264367816091955\n",
      "Early stopping counter 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 18/45 [15:54<21:17, 47.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train loss: 0.6183839870823754, Acc: 0.6729776247848537, F1-Macro: 0.6720439691027926\n",
      "Epoch 18, Val loss: 0.8601936995983124, Acc: 0.7384615384615385, F1-Macro: 0.7321212121212122\n",
      "Early stopping counter 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42% 19/45 [16:39<20:12, 46.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train loss: 0.6501891513665518, Acc: 0.6660929432013769, F1-Macro: 0.6644218173157082\n",
      "Epoch 19, Val loss: 0.8532657623291016, Acc: 0.676923076923077, F1-Macro: 0.676923076923077\n",
      "Early stopping counter 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44% 20/45 [17:25<19:22, 46.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train loss: 0.6059776627355151, Acc: 0.6712564543889845, F1-Macro: 0.6661291244580703\n",
      "Epoch 20, Val loss: 1.3307647556066513, Acc: 0.7230769230769231, F1-Macro: 0.7176640926640927\n",
      "Early stopping counter 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47% 21/45 [18:11<18:34, 46.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Train loss: 0.5916804886526532, Acc: 0.6884681583476764, F1-Macro: 0.6814895582511775\n",
      "Epoch 21, Val loss: 1.2116356492042542, Acc: 0.47692307692307695, F1-Macro: 0.4551282051282051\n",
      "Early stopping counter 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% 22/45 [18:55<17:27, 45.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Train loss: 0.6286279062430064, Acc: 0.693631669535284, F1-Macro: 0.6878606784981287\n",
      "Epoch 22, Val loss: 0.7766777276992798, Acc: 0.6615384615384615, F1-Macro: 0.6614583333333333\n",
      "Validation loss decreased 0.7939962297677994 -> 0.7766777276992798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51% 23/45 [19:41<16:49, 45.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Train loss: 0.5879577282402251, Acc: 0.7469879518072289, F1-Macro: 0.746118517857939\n",
      "Epoch 23, Val loss: 1.0188232511281967, Acc: 0.7846153846153846, F1-Macro: 0.7833333333333333\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53% 24/45 [20:27<16:03, 45.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train loss: 0.5657293316390779, Acc: 0.7504302925989673, F1-Macro: 0.7501342088794375\n",
      "Epoch 24, Val loss: 1.6814464181661606, Acc: 0.676923076923077, F1-Macro: 0.6719538572458543\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56% 25/45 [21:12<15:10, 45.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Train loss: 0.5333758989969889, Acc: 0.7194492254733219, F1-Macro: 0.7178309124767226\n",
      "Epoch 25, Val loss: 0.8932109773159027, Acc: 0.7230769230769231, F1-Macro: 0.7075\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58% 26/45 [21:57<14:23, 45.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Train loss: 0.5520549615224203, Acc: 0.7573149741824441, F1-Macro: 0.757312098401159\n",
      "Epoch 26, Val loss: 0.7375549674034119, Acc: 0.6307692307692307, F1-Macro: 0.6153846153846154\n",
      "Validation loss decreased 0.7766777276992798 -> 0.7375549674034119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 27/45 [22:42<13:31, 45.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Train loss: 0.5490862727165222, Acc: 0.7487091222030982, F1-Macro: 0.7477938727938729\n",
      "Epoch 27, Val loss: 1.0446853637695312, Acc: 0.7384615384615385, F1-Macro: 0.7292330311198234\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62% 28/45 [23:27<12:50, 45.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Train loss: 0.5565780285331938, Acc: 0.7555938037865749, F1-Macro: 0.7547036297036298\n",
      "Epoch 28, Val loss: 0.48686401080340147, Acc: 0.7538461538461538, F1-Macro: 0.7533206831119544\n",
      "Validation loss decreased 0.7375549674034119 -> 0.48686401080340147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64% 29/45 [24:12<12:02, 45.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Train loss: 0.49779383341471356, Acc: 0.7796901893287436, F1-Macro: 0.7796738718240425\n",
      "Epoch 29, Val loss: 0.8021396100521088, Acc: 0.6923076923076923, F1-Macro: 0.6794871794871795\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67% 30/45 [24:58<11:18, 45.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train loss: 0.4675469473004341, Acc: 0.7676419965576592, F1-Macro: 0.7673083598109631\n",
      "Epoch 30, Val loss: 0.6235245615243912, Acc: 0.7384615384615385, F1-Macro: 0.7292330311198236\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69% 31/45 [25:43<10:34, 45.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Train loss: 0.4470035798019833, Acc: 0.7969018932874354, F1-Macro: 0.7964623313699412\n",
      "Epoch 31, Val loss: 0.5944847781211138, Acc: 0.6923076923076923, F1-Macro: 0.6862934362934363\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71% 32/45 [26:28<09:49, 45.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Train loss: 0.4558476118577851, Acc: 0.7865748709122203, F1-Macro: 0.7861129583887517\n",
      "Epoch 32, Val loss: 0.8070237189531326, Acc: 0.7230769230769231, F1-Macro: 0.7176640926640927\n",
      "Early stopping counter 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73% 33/45 [27:13<09:01, 45.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Train loss: 0.4928646402226554, Acc: 0.8089500860585198, F1-Macro: 0.8088934721345578\n",
      "Epoch 33, Val loss: 0.7257777750492096, Acc: 0.8307692307692308, F1-Macro: 0.8307692307692308\n",
      "Early stopping counter 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76% 34/45 [27:58<08:16, 45.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Train loss: 0.4595480395687951, Acc: 0.8003442340791739, F1-Macro: 0.800173154012192\n",
      "Epoch 34, Val loss: 0.8189022839069366, Acc: 0.7692307692307693, F1-Macro: 0.7656813266041816\n",
      "Early stopping counter 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78% 35/45 [28:44<07:33, 45.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Train loss: 0.4157434155543645, Acc: 0.8141135972461274, F1-Macro: 0.8138704318936877\n",
      "Epoch 35, Val loss: 0.5345329671981744, Acc: 0.8, F1-Macro: 0.7969238163902908\n",
      "Early stopping counter 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 36/45 [29:30<06:50, 45.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Train loss: 0.4720372408628464, Acc: 0.8089500860585198, F1-Macro: 0.8086235292372064\n",
      "Epoch 36, Val loss: 0.5488572269678116, Acc: 0.7846153846153846, F1-Macro: 0.7804054054054055\n",
      "Early stopping counter 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82% 37/45 [30:14<06:00, 45.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Train loss: 0.4103667388359706, Acc: 0.8141135972461274, F1-Macro: 0.8138218329416791\n",
      "Epoch 37, Val loss: 0.6326702684164047, Acc: 0.8153846153846154, F1-Macro: 0.8149905123339658\n",
      "Early stopping counter 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84% 38/45 [30:59<05:16, 45.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Train loss: 0.42889462576972115, Acc: 0.8278829604130808, F1-Macro: 0.8273915626856804\n",
      "Epoch 38, Val loss: 0.42186273221159354, Acc: 0.8, F1-Macro: 0.799239724400095\n",
      "Validation loss decreased 0.48686401080340147 -> 0.42186273221159354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87% 39/45 [31:44<04:29, 44.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Train loss: 0.39939094748761916, Acc: 0.8433734939759037, F1-Macro: 0.8432230152681941\n",
      "Epoch 39, Val loss: 0.6156798079609871, Acc: 0.7692307692307693, F1-Macro: 0.7690120824449184\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89% 40/45 [32:29<03:44, 44.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Train loss: 0.3584972843527794, Acc: 0.8537005163511188, F1-Macro: 0.8535599593164452\n",
      "Epoch 40, Val loss: 0.5008388505666517, Acc: 0.7846153846153846, F1-Macro: 0.7845643939393939\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91% 41/45 [33:14<02:59, 44.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Train loss: 0.36797722180684406, Acc: 0.8674698795180723, F1-Macro: 0.8673928830791577\n",
      "Epoch 41, Val loss: 1.280441790819168, Acc: 0.7846153846153846, F1-Macro: 0.7841555977229602\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93% 42/45 [34:00<02:15, 45.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Train loss: 0.3557793100674947, Acc: 0.846815834767642, F1-Macro: 0.8466341006225513\n",
      "Epoch 42, Val loss: 0.5205321609973907, Acc: 0.8, F1-Macro: 0.799239724400095\n",
      "Early stopping counter 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96% 43/45 [34:45<01:30, 45.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Train loss: 0.3470737826493051, Acc: 0.8657487091222031, F1-Macro: 0.865729218516675\n",
      "Epoch 43, Val loss: 1.0487292408943176, Acc: 0.7384615384615385, F1-Macro: 0.7374673319078165\n",
      "Early stopping counter 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98% 44/45 [35:30<00:45, 45.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Train loss: 0.3731638292471568, Acc: 0.846815834767642, F1-Macro: 0.8465958816531534\n",
      "Epoch 44, Val loss: 0.9456693232059479, Acc: 0.8153846153846154, F1-Macro: 0.8149905123339658\n",
      "Early stopping counter 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 45/45 [36:17<00:00, 48.38s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch_index in tqdm(range(EPOCHS)):\n",
    "\n",
    "    trainer.train_epoch(train_dataloader, epoch_index)\n",
    "    trainer.validate_epoch(validation_dataloader, epoch_index)\n",
    "    \n",
    "    # early_stopping check\n",
    "    early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
    "\n",
    "    if early_stopper.stop:\n",
    "        print('Early stopped')\n",
    "        break\n",
    "\n",
    "    if early_stopper.save_model:\n",
    "        check_point = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "        }\n",
    "        torch.save(check_point, 'best.pt')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3139a08-162d-4fde-a8d2-cb57774b7141",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL_PATH = 'best.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e761a971-465d-4357-a7f4-37b413a7d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_dir, input_shape):\n",
    "        self.data_dir = data_dir\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Loading dataset\n",
    "        self.db = self.data_loader()\n",
    "        \n",
    "        # Transform function\n",
    "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading test dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        db = pd.read_csv(os.path.join(self.data_dir, 'sample_submission.csv'))\n",
    "        return db\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "        \n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(os.path.join(self.data_dir,'test',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
    "\n",
    "        # Preprocessing images\n",
    "        trans_image = self.transform(Image.fromarray(cvimg))\n",
    "\n",
    "        return trans_image, data['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b91de010-b89d-485e-862a-a74fda70fcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset..\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "test_dataset = TestDataset(data_dir=DATA_DIR, input_shape=INPUT_SHAPE)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caaeaeca-1c34-4b0a-8d53-53067d2a1515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.7893e-01, 2.1071e-02],\n",
      "        [3.2508e-01, 6.7492e-01],\n",
      "        [2.7105e-01, 7.2895e-01],\n",
      "        [7.0985e-01, 2.9015e-01],\n",
      "        [7.3383e-01, 2.6617e-01],\n",
      "        [1.5087e-01, 8.4913e-01],\n",
      "        [3.9055e-01, 6.0945e-01],\n",
      "        [2.0742e-01, 7.9258e-01],\n",
      "        [8.8456e-01, 1.1544e-01],\n",
      "        [1.2427e-03, 9.9876e-01],\n",
      "        [9.6019e-01, 3.9814e-02],\n",
      "        [9.4739e-01, 5.2608e-02],\n",
      "        [9.8818e-01, 1.1816e-02],\n",
      "        [9.9884e-01, 1.1584e-03],\n",
      "        [6.0097e-01, 3.9903e-01],\n",
      "        [8.4958e-01, 1.5042e-01],\n",
      "        [3.8673e-01, 6.1327e-01],\n",
      "        [9.9932e-01, 6.7980e-04],\n",
      "        [2.1473e-01, 7.8527e-01],\n",
      "        [9.9177e-01, 8.2292e-03],\n",
      "        [9.9798e-01, 2.0186e-03],\n",
      "        [9.6569e-01, 3.4312e-02],\n",
      "        [6.4185e-01, 3.5815e-01],\n",
      "        [5.7984e-01, 4.2016e-01],\n",
      "        [6.4879e-02, 9.3512e-01],\n",
      "        [9.3990e-01, 6.0098e-02],\n",
      "        [3.3832e-01, 6.6168e-01],\n",
      "        [6.9132e-01, 3.0868e-01],\n",
      "        [5.4692e-03, 9.9453e-01],\n",
      "        [8.1799e-01, 1.8201e-01],\n",
      "        [1.9391e-02, 9.8061e-01],\n",
      "        [9.7870e-02, 9.0213e-01]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:04,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9310, 0.0690],\n",
      "        [0.6219, 0.3781],\n",
      "        [0.6752, 0.3248],\n",
      "        [0.4777, 0.5223],\n",
      "        [0.2549, 0.7451],\n",
      "        [0.2557, 0.7443],\n",
      "        [0.0856, 0.9144],\n",
      "        [0.2613, 0.7387],\n",
      "        [0.3142, 0.6858],\n",
      "        [0.5825, 0.4175],\n",
      "        [0.9210, 0.0790],\n",
      "        [0.0160, 0.9840],\n",
      "        [0.0568, 0.9432],\n",
      "        [0.2560, 0.7440],\n",
      "        [0.7500, 0.2500],\n",
      "        [0.9951, 0.0049],\n",
      "        [0.2601, 0.7399],\n",
      "        [0.9311, 0.0689],\n",
      "        [0.8452, 0.1548],\n",
      "        [0.0556, 0.9444],\n",
      "        [0.1351, 0.8649],\n",
      "        [0.4023, 0.5977],\n",
      "        [0.3280, 0.6720],\n",
      "        [0.0777, 0.9223],\n",
      "        [0.9151, 0.0849],\n",
      "        [0.1934, 0.8066],\n",
      "        [0.9282, 0.0718],\n",
      "        [0.3738, 0.6262],\n",
      "        [0.0452, 0.9548],\n",
      "        [0.9293, 0.0707],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.9503, 0.0497]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:06,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.4771e-01, 6.5229e-01],\n",
      "        [3.0911e-03, 9.9691e-01],\n",
      "        [1.7689e-01, 8.2311e-01],\n",
      "        [9.2677e-01, 7.3235e-02],\n",
      "        [1.9732e-02, 9.8027e-01],\n",
      "        [7.2010e-01, 2.7990e-01],\n",
      "        [9.8859e-01, 1.1408e-02],\n",
      "        [9.6082e-01, 3.9183e-02],\n",
      "        [3.1866e-01, 6.8134e-01],\n",
      "        [9.9994e-01, 6.3411e-05],\n",
      "        [6.7151e-01, 3.2849e-01],\n",
      "        [9.9561e-01, 4.3885e-03],\n",
      "        [9.9957e-01, 4.2590e-04],\n",
      "        [9.9995e-01, 4.5243e-05],\n",
      "        [1.4820e-01, 8.5180e-01],\n",
      "        [1.6186e-01, 8.3814e-01],\n",
      "        [2.4567e-01, 7.5433e-01],\n",
      "        [1.7081e-01, 8.2919e-01],\n",
      "        [9.6399e-01, 3.6015e-02],\n",
      "        [1.7530e-01, 8.2470e-01],\n",
      "        [3.5253e-01, 6.4747e-01],\n",
      "        [4.5808e-01, 5.4192e-01],\n",
      "        [8.5741e-01, 1.4259e-01],\n",
      "        [7.8840e-02, 9.2116e-01],\n",
      "        [9.9377e-01, 6.2290e-03],\n",
      "        [9.0683e-01, 9.3167e-02],\n",
      "        [9.9012e-01, 9.8796e-03],\n",
      "        [8.6430e-01, 1.3570e-01],\n",
      "        [4.4071e-02, 9.5593e-01],\n",
      "        [4.8572e-02, 9.5143e-01],\n",
      "        [9.9776e-01, 2.2432e-03],\n",
      "        [9.9271e-01, 7.2920e-03]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:06,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1248, 0.8752],\n",
      "        [0.2135, 0.7865],\n",
      "        [0.0035, 0.9965],\n",
      "        [0.4246, 0.5754]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])\n",
    "\n",
    "# Prediction\n",
    "file_lst = []\n",
    "pred_lst = []\n",
    "prob_lst = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_index, (img, file_num) in tqdm(enumerate(test_dataloader)):\n",
    "        img = img.to(DEVICE)\n",
    "        pred = model(img)\n",
    "        print(pred)\n",
    "        file_lst.extend(list(file_num))\n",
    "        pred_lst.extend(pred.argmax(dim=1).tolist())\n",
    "        prob_lst.extend(pred[:, 1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "123f2d7b-ffa5-4b50-abc6-9a6353e8d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'file_name':file_lst, 'COVID':pred_lst})\n",
    "# df.sort_values(by=['file_name'], inplace=True)\n",
    "df.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa5ffb-2d74-4d74-a3af-ae79b5a6b2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21cf2c09-fbc0-45b5-bd83-0d91c81cef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.7893e-01, 2.1071e-02],\n",
      "        [3.2508e-01, 6.7492e-01],\n",
      "        [2.7105e-01, 7.2895e-01],\n",
      "        [7.0985e-01, 2.9015e-01],\n",
      "        [7.3383e-01, 2.6617e-01],\n",
      "        [1.5087e-01, 8.4913e-01],\n",
      "        [3.9055e-01, 6.0945e-01],\n",
      "        [2.0742e-01, 7.9258e-01],\n",
      "        [8.8456e-01, 1.1544e-01],\n",
      "        [1.2427e-03, 9.9876e-01],\n",
      "        [9.6019e-01, 3.9814e-02],\n",
      "        [9.4739e-01, 5.2608e-02],\n",
      "        [9.8818e-01, 1.1816e-02],\n",
      "        [9.9884e-01, 1.1584e-03],\n",
      "        [6.0097e-01, 3.9903e-01],\n",
      "        [8.4958e-01, 1.5042e-01],\n",
      "        [3.8673e-01, 6.1327e-01],\n",
      "        [9.9932e-01, 6.7980e-04],\n",
      "        [2.1473e-01, 7.8527e-01],\n",
      "        [9.9177e-01, 8.2292e-03],\n",
      "        [9.9798e-01, 2.0186e-03],\n",
      "        [9.6569e-01, 3.4312e-02],\n",
      "        [6.4185e-01, 3.5815e-01],\n",
      "        [5.7984e-01, 4.2016e-01],\n",
      "        [6.4879e-02, 9.3512e-01],\n",
      "        [9.3990e-01, 6.0098e-02],\n",
      "        [3.3832e-01, 6.6168e-01],\n",
      "        [6.9132e-01, 3.0868e-01],\n",
      "        [5.4692e-03, 9.9453e-01],\n",
      "        [8.1799e-01, 1.8201e-01],\n",
      "        [1.9391e-02, 9.8061e-01],\n",
      "        [9.7870e-02, 9.0213e-01]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:04,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9310, 0.0690],\n",
      "        [0.6219, 0.3781],\n",
      "        [0.6752, 0.3248],\n",
      "        [0.4777, 0.5223],\n",
      "        [0.2549, 0.7451],\n",
      "        [0.2557, 0.7443],\n",
      "        [0.0856, 0.9144],\n",
      "        [0.2613, 0.7387],\n",
      "        [0.3142, 0.6858],\n",
      "        [0.5825, 0.4175],\n",
      "        [0.9210, 0.0790],\n",
      "        [0.0160, 0.9840],\n",
      "        [0.0568, 0.9432],\n",
      "        [0.2560, 0.7440],\n",
      "        [0.7500, 0.2500],\n",
      "        [0.9951, 0.0049],\n",
      "        [0.2601, 0.7399],\n",
      "        [0.9311, 0.0689],\n",
      "        [0.8452, 0.1548],\n",
      "        [0.0556, 0.9444],\n",
      "        [0.1351, 0.8649],\n",
      "        [0.4023, 0.5977],\n",
      "        [0.3280, 0.6720],\n",
      "        [0.0777, 0.9223],\n",
      "        [0.9151, 0.0849],\n",
      "        [0.1934, 0.8066],\n",
      "        [0.9282, 0.0718],\n",
      "        [0.3738, 0.6262],\n",
      "        [0.0452, 0.9548],\n",
      "        [0.9293, 0.0707],\n",
      "        [0.9940, 0.0060],\n",
      "        [0.9503, 0.0497]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:06,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.4771e-01, 6.5229e-01],\n",
      "        [3.0911e-03, 9.9691e-01],\n",
      "        [1.7689e-01, 8.2311e-01],\n",
      "        [9.2677e-01, 7.3235e-02],\n",
      "        [1.9732e-02, 9.8027e-01],\n",
      "        [7.2010e-01, 2.7990e-01],\n",
      "        [9.8859e-01, 1.1408e-02],\n",
      "        [9.6082e-01, 3.9183e-02],\n",
      "        [3.1866e-01, 6.8134e-01],\n",
      "        [9.9994e-01, 6.3411e-05],\n",
      "        [6.7151e-01, 3.2849e-01],\n",
      "        [9.9561e-01, 4.3885e-03],\n",
      "        [9.9957e-01, 4.2590e-04],\n",
      "        [9.9995e-01, 4.5243e-05],\n",
      "        [1.4820e-01, 8.5180e-01],\n",
      "        [1.6186e-01, 8.3814e-01],\n",
      "        [2.4567e-01, 7.5433e-01],\n",
      "        [1.7081e-01, 8.2919e-01],\n",
      "        [9.6399e-01, 3.6015e-02],\n",
      "        [1.7530e-01, 8.2470e-01],\n",
      "        [3.5253e-01, 6.4747e-01],\n",
      "        [4.5808e-01, 5.4192e-01],\n",
      "        [8.5741e-01, 1.4259e-01],\n",
      "        [7.8840e-02, 9.2116e-01],\n",
      "        [9.9377e-01, 6.2290e-03],\n",
      "        [9.0683e-01, 9.3167e-02],\n",
      "        [9.9012e-01, 9.8796e-03],\n",
      "        [8.6430e-01, 1.3570e-01],\n",
      "        [4.4071e-02, 9.5593e-01],\n",
      "        [4.8572e-02, 9.5143e-01],\n",
      "        [9.9776e-01, 2.2432e-03],\n",
      "        [9.9271e-01, 7.2920e-03]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:07,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1248, 0.8752],\n",
      "        [0.2135, 0.7865],\n",
      "        [0.0035, 0.9965],\n",
      "        [0.4246, 0.5754]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "file_lst = []\n",
    "pred_lst = []\n",
    "prob_lst = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_index, (img, file_num) in tqdm(enumerate(test_dataloader)):\n",
    "        img = img.to(DEVICE)\n",
    "        pred = model(img)\n",
    "        print(pred)\n",
    "        file_lst.extend(list(file_num))\n",
    "        pred_lst.extend(pred.tolist())\n",
    "df = pd.DataFrame(pred_lst)\n",
    "# df.sort_values(by=['file_name'], inplace=True)\n",
    "df.to_csv('prediction111.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3462f-f113-493a-b35e-124902e7630e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
